{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json\n",
    "nlp = StanfordCoreNLP(r'D:\\pythonProject\\coreNLP\\stanford-corenlp', memory='8g')\n",
    "#stanford-corenlp download in http://nlp.stanford.edu/software/stanford-corenlp-full-2018-02-27.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreNLP Function Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence = 'Guangdong University of Foreign Studies is located in Guangzhou.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize: ['Guangdong', 'University', 'of', 'Foreign', 'Studies', 'is', 'located', 'in', 'Guangzhou', '.']\n"
     ]
    }
   ],
   "source": [
    "print('Tokenize:', nlp.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of Speech: [('Guangdong', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Foreign', 'NNP'), ('Studies', 'NNPS'), ('is', 'VBZ'), ('located', 'JJ'), ('in', 'IN'), ('Guangzhou', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print('Part of Speech:', nlp.pos_tag(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [('Guangdong', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('of', 'ORGANIZATION'), ('Foreign', 'ORGANIZATION'), ('Studies', 'ORGANIZATION'), ('is', 'O'), ('located', 'O'), ('in', 'O'), ('Guangzhou', 'CITY'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print('Named Entities:', nlp.ner(sentence) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constituency Parsing: (ROOT\r\n",
      "  (S\r\n",
      "    (NP\r\n",
      "      (NP (NNP Guangdong) (NNP University))\r\n",
      "      (PP (IN of)\r\n",
      "        (NP (NNP Foreign) (NNPS Studies))))\r\n",
      "    (VP (VBZ is)\r\n",
      "      (ADJP (JJ located)\r\n",
      "        (PP (IN in)\r\n",
      "          (NP (NNP Guangzhou)))))\r\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "print ('Constituency Parsing:', nlp.parse(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency Parsing: [('ROOT', 0, 7), ('compound', 2, 1), ('nsubjpass', 7, 2), ('case', 5, 3), ('compound', 5, 4), ('nmod', 2, 5), ('auxpass', 7, 6), ('case', 9, 8), ('nmod', 7, 9), ('punct', 7, 10)]\n"
     ]
    }
   ],
   "source": [
    "print ('Dependency Parsing:', nlp.dependency_parse(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coreference Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = 'Barack Obama was born in Hawaii. He is the president. Obama was elected in 2008.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "props={'annotators': 'dcoref','pipelineLanguage':'en','outputFormat':'json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_dict = json.loads(nlp.annotate(text, properties=props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: 1\n",
      "{'id': 1, 'text': 'Barack Obama', 'type': 'PROPER', 'number': 'SINGULAR', 'gender': 'MALE', 'animacy': 'ANIMATE', 'startIndex': 1, 'endIndex': 3, 'headIndex': 2, 'sentNum': 1, 'position': [1, 1], 'isRepresentativeMention': True}\n",
      "{'id': 3, 'text': 'He', 'type': 'PRONOMINAL', 'number': 'SINGULAR', 'gender': 'MALE', 'animacy': 'ANIMATE', 'startIndex': 1, 'endIndex': 2, 'headIndex': 1, 'sentNum': 2, 'position': [2, 1], 'isRepresentativeMention': False}\n",
      "{'id': 4, 'text': 'the president', 'type': 'NOMINAL', 'number': 'SINGULAR', 'gender': 'MALE', 'animacy': 'ANIMATE', 'startIndex': 3, 'endIndex': 5, 'headIndex': 4, 'sentNum': 2, 'position': [2, 2], 'isRepresentativeMention': False}\n",
      "{'id': 5, 'text': 'Obama', 'type': 'PROPER', 'number': 'SINGULAR', 'gender': 'MALE', 'animacy': 'ANIMATE', 'startIndex': 1, 'endIndex': 2, 'headIndex': 1, 'sentNum': 3, 'position': [3, 1], 'isRepresentativeMention': False}\n",
      "Entity: 2\n",
      "{'id': 2, 'text': 'Hawaii', 'type': 'PROPER', 'number': 'SINGULAR', 'gender': 'NEUTRAL', 'animacy': 'INANIMATE', 'startIndex': 6, 'endIndex': 7, 'headIndex': 6, 'sentNum': 1, 'position': [1, 2], 'isRepresentativeMention': True}\n",
      "Entity: 6\n",
      "{'id': 6, 'text': '2008', 'type': 'PROPER', 'number': 'SINGULAR', 'gender': 'UNKNOWN', 'animacy': 'INANIMATE', 'startIndex': 5, 'endIndex': 6, 'headIndex': 5, 'sentNum': 3, 'position': [3, 2], 'isRepresentativeMention': True}\n"
     ]
    }
   ],
   "source": [
    "for idx, mentions in result_dict['corefs'].items():\n",
    "    print('Entity:', idx)\n",
    "    for m in mentions:\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coreference Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/coref.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1, 1, 2, 'My'), (2, 4, 5, 'me')], [(1, 1, 3, 'My sister'), (3, 1, 2, 'She')], [(1, 7, 8, 'John'), (2, 7, 8, 'him'), (3, 3, 4, 'he')]]\n"
     ]
    }
   ],
   "source": [
    "##Each tuple represents (sentence_index, start_index, end_index, text), starts with 1-index##\n",
    "text = \"My sister has a friend called John. Really, tell me more about him? She think he is so funny!\"\n",
    "print(nlp.coref(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: 4\n",
      "{'id': 1, 'text': 'My', 'type': 'PRONOMINAL', 'number': 'SINGULAR', 'gender': 'UNKNOWN', 'animacy': 'ANIMATE', 'startIndex': 1, 'endIndex': 2, 'headIndex': 1, 'sentNum': 1, 'position': [1, 2], 'isRepresentativeMention': True}\n",
      "{'id': 4, 'text': 'me', 'type': 'PRONOMINAL', 'number': 'SINGULAR', 'gender': 'UNKNOWN', 'animacy': 'ANIMATE', 'startIndex': 4, 'endIndex': 5, 'headIndex': 4, 'sentNum': 2, 'position': [2, 1], 'isRepresentativeMention': False}\n",
      "Entity: 6\n",
      "{'id': 2, 'text': 'My sister', 'type': 'NOMINAL', 'number': 'SINGULAR', 'gender': 'FEMALE', 'animacy': 'ANIMATE', 'startIndex': 1, 'endIndex': 3, 'headIndex': 2, 'sentNum': 1, 'position': [1, 3], 'isRepresentativeMention': True}\n",
      "{'id': 6, 'text': 'She', 'type': 'PRONOMINAL', 'number': 'SINGULAR', 'gender': 'FEMALE', 'animacy': 'ANIMATE', 'startIndex': 1, 'endIndex': 2, 'headIndex': 1, 'sentNum': 3, 'position': [3, 1], 'isRepresentativeMention': False}\n",
      "Entity: 7\n",
      "{'id': 0, 'text': 'John', 'type': 'PROPER', 'number': 'SINGULAR', 'gender': 'MALE', 'animacy': 'ANIMATE', 'startIndex': 7, 'endIndex': 8, 'headIndex': 7, 'sentNum': 1, 'position': [1, 1], 'isRepresentativeMention': True}\n",
      "{'id': 5, 'text': 'him', 'type': 'PRONOMINAL', 'number': 'SINGULAR', 'gender': 'MALE', 'animacy': 'ANIMATE', 'startIndex': 7, 'endIndex': 8, 'headIndex': 7, 'sentNum': 2, 'position': [2, 2], 'isRepresentativeMention': False}\n",
      "{'id': 7, 'text': 'he', 'type': 'PRONOMINAL', 'number': 'SINGULAR', 'gender': 'MALE', 'animacy': 'ANIMATE', 'startIndex': 3, 'endIndex': 4, 'headIndex': 3, 'sentNum': 3, 'position': [3, 2], 'isRepresentativeMention': False}\n"
     ]
    }
   ],
   "source": [
    "pros = {'annotators': 'coref', 'pinelineLanguage': 'en'}\n",
    "result_dict = json.loads(nlp.annotate(text, properties=pros))\n",
    "\n",
    "for idx, mentions in result_dict['corefs'].items():\n",
    "    print('Entity:', idx)\n",
    "    for m in mentions:\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "sentNum: 1\n",
      "startIndex: 1\n",
      "endIndex: 2\n",
      "text: My\n",
      "########################\n",
      "sentNum: 2\n",
      "startIndex: 4\n",
      "endIndex: 5\n",
      "text: me\n",
      "########################\n",
      "-----------\n",
      "sentNum: 1\n",
      "startIndex: 1\n",
      "endIndex: 3\n",
      "text: My sister\n",
      "########################\n",
      "sentNum: 3\n",
      "startIndex: 1\n",
      "endIndex: 2\n",
      "text: She\n",
      "########################\n",
      "-----------\n",
      "sentNum: 1\n",
      "startIndex: 7\n",
      "endIndex: 8\n",
      "text: John\n",
      "########################\n",
      "sentNum: 2\n",
      "startIndex: 7\n",
      "endIndex: 8\n",
      "text: him\n",
      "########################\n",
      "sentNum: 3\n",
      "startIndex: 3\n",
      "endIndex: 4\n",
      "text: he\n",
      "########################\n"
     ]
    }
   ],
   "source": [
    "for idx, mentions in result_dict['corefs'].items():\n",
    "    print('-----------')\n",
    "    for m in mentions:\n",
    "        print('sentNum: ' + str(m['sentNum']))\n",
    "        print('startIndex: ' + str(m['startIndex']))\n",
    "        print('endIndex: ' + str(m['endIndex']))\n",
    "        print('text: ' + m['text'])\n",
    "        print('########################')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
